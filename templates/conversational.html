<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Conversational Historical Figures Game</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
            overflow-x: hidden;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            animation: slideInDown 0.8s ease-out;
        }
        .title {
            font-size: 2.5rem;
            font-weight: bold;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            margin-bottom: 10px;
        }
        .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        .conversation-card {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            margin: 20px 0;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            animation: slideInUp 0.8s ease-out;
            transition: all 0.3s ease;
        }

        /* Speech Text Display */
        .speech-text-display {
            position: fixed;
            top: 20px;
            left: 20px;
            right: 20px;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 15px;
            border-radius: 10px;
            font-size: 1.1rem;
            z-index: 1000;
            animation: slideInDown 0.3s ease-out;
            border: 2px solid #4CAF50;
        }

        /* Conversation States */
        .conversation-state {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 1.1rem;
            transition: all 0.3s ease;
        }
        .state-speaking {
            background: rgba(76, 175, 80, 0.2);
            border: 2px solid rgba(76, 175, 80, 0.5);
            animation: speakingPulse 2s infinite;
        }
        .state-listening {
            background: rgba(33, 150, 243, 0.2);
            border: 2px solid rgba(33, 150, 243, 0.5);
            animation: listeningPulse 1.5s infinite;
        }
        .state-processing {
            background: rgba(156, 39, 176, 0.2);
            border: 2px solid rgba(156, 39, 176, 0.5);
            animation: processingPulse 1s infinite;
        }
        .state-waiting {
            background: rgba(255, 193, 7, 0.2);
            border: 2px solid rgba(255, 193, 7, 0.5);
            animation: waitingPulse 2.5s infinite;
        }

        @keyframes speakingPulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.8; transform: scale(1.05); }
        }
        @keyframes listeningPulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        @keyframes processingPulse {
            0%, 100% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        @keyframes waitingPulse {
            0%, 100% { opacity: 1; }
            25%, 75% { opacity: 0.6; }
        }

        /* Audio Visualizer - FROM INDEX.HTML */
        .audio-visualizer {
            display: flex;
            justify-content: center;
            align-items: flex-end;
            height: 60px;
            margin: 20px 0;
            gap: 3px;
        }
        .audio-bar {
            width: 4px;
            background: linear-gradient(to top, #FF6B6B, #FF8E53);
            border-radius: 2px;
            opacity: 0.3;
            transition: all 0.1s ease;
        }
        .audio-bar.active {
            opacity: 1;
            animation: audioWave 0.5s ease-in-out infinite alternate;
        }
        @keyframes audioWave {
            0% { transform: scaleY(0.1); }
            100% { transform: scaleY(1); }
        }

        /* Progress and Score */
        .progress-section {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 25px;
            flex-wrap: wrap;
            gap: 15px;
        }
        .progress-bar {
            flex: 1;
            height: 12px;
            background: rgba(255,255,255,0.2);
            border-radius: 6px;
            overflow: hidden;
            min-width: 200px;
        }
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #45a049);
            border-radius: 6px;
            transition: width 0.8s ease;
        }
        .score-display {
            font-size: 1.3rem;
            font-weight: bold;
            text-align: right;
        }

        /* Figure Description */
        .figure-description {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            margin-bottom: 25px;
            border-left: 4px solid #FFD700;
        }

        /* Controls */
        .conversation-controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .conv-button {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
            font-weight: bold;
        }
        .conv-button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        .conv-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .conv-button.primary {
            background: linear-gradient(135deg, #4CAF50, #45a049);
        }
        .conv-button.secondary {
            background: linear-gradient(135deg, #FF9800, #F57C00);
        }
        .conv-button.danger {
            background: linear-gradient(135deg, #F44336, #D32F2F);
        }

        /* Results Display */
        .conversation-result {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            margin: 15px 0;
            animation: slideInUp 0.6s ease-out;
        }
        .result-score {
            font-size: 1.5rem;
            font-weight: bold;
            text-align: center;
            margin-bottom: 15px;
        }

        /* Error Messages */
        .error-message {
            background: rgba(244, 67, 54, 0.2);
            border: 1px solid rgba(244, 67, 54, 0.5);
            color: #ff6b6b;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            text-align: center;
            animation: shake 0.5s ease-in-out;
        }
        @keyframes shake {
            0%, 100% { transform: translateX(0); }
            25% { transform: translateX(-5px); }
            75% { transform: translateX(5px); }
        }

        /* Permission Request */
        .permission-request {
            text-align: center;
            padding: 30px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            margin: 20px 0;
        }

        /* Mode Toggle */
        .mode-toggle {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-bottom: 20px;
        }
        .mode-button {
            padding: 10px 20px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .mode-button.active {
            background: rgba(255, 255, 255, 0.3);
            border-color: rgba(255, 255, 255, 0.6);
        }

        /* Debug Panel */
        .debug-panel {
            background: rgba(0,0,0,0.2);
            padding: 10px;
            border-radius: 10px;
            font-family: monospace;
            font-size: 0.8rem;
            margin: 10px 0;
            display: none;
        }

        @keyframes slideInDown {
            from { opacity: 0; transform: translateY(-50px); }
            to { opacity: 1; transform: translateY(0); }
        }
        @keyframes slideInUp {
            from { opacity: 0; transform: translateY(50px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @media (max-width: 768px) {
            .container { padding: 15px; }
            .title { font-size: 2rem; }
            .conversation-card { padding: 20px; }
            .conversation-controls { flex-direction: column; }
            .conv-button { width: 100%; }
            .speech-text-display {
                left: 10px;
                right: 10px;
                font-size: 1rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="title">üéôÔ∏è Conversational History Game</h1>
            <p class="subtitle">Speak naturally with your AI tutor about historical figures!</p>
        </div>

        <div class="mode-toggle">
            <button class="mode-button" id="manualMode" onclick="setMode('manual')">Manual Mode</button>
            <button class="mode-button active" id="conversationalMode" onclick="setMode('conversational')">Conversational Mode</button>
        </div>

        <div id="gameContainer">
            <div class="conversation-card">
                <div class="permission-request">
                    <h3>üé§ Microphone Permission Required</h3>
                    <p>This conversational mode needs microphone access to hear your responses.</p>
                    <button class="conv-button primary" onclick="game.requestPermissions()">Grant Permission & Start</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        class ConversationalHistoryGame {
            constructor() {
                // USING AUDIO PROCESSING FROM INDEX.HTML BUT KEEPING CONVERSATIONAL FLOW
                this.mediaRecorder = null;
                this.isRecording = false;
                this.isProcessing = false;
                this.gameState = null;
                this.audioContext = null;
                this.analyser = null;
                this.dataArray = null;
                this.permissionsGranted = false;
                this.speechSynthesis = null;
                this.currentUtterance = null;
                this.lastUserInteraction = Date.now();
                this.isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);

                // Conversational flow states
                this.conversationState = 'idle';

                // Auto-recording detection (using reliable logic from index.html)
                this.vadTimer = null;
                this.speechDetected = false;
                this.silenceStartTime = null;
                this.recordingStartTime = null;

                // Track interaction for iOS speech synthesis
                document.addEventListener('click', () => this.trackUserInteraction());
                document.addEventListener('touchstart', () => this.trackUserInteraction());

                this.init();
            }

            async init() {
                this.setupSpeechSynthesis();
                this.checkBrowserSupport();
            }

            trackUserInteraction() {
                this.lastUserInteraction = Date.now();
                console.log('üëÜ User interaction tracked');
            }

            checkBrowserSupport() {
                const errors = [];
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    errors.push("Microphone access not supported");
                }
                if (!window.SpeechSynthesisUtterance) {
                    errors.push("Text-to-speech not supported");
                }
                if (errors.length > 0) {
                    this.showError("Browser not supported: " + errors.join(", "));
                    return false;
                }
                return true;
            }

            setupSpeechSynthesis() {
                this.speechSynthesis = window.speechSynthesis;
                if (this.speechSynthesis.getVoices().length === 0) {
                    this.speechSynthesis.addEventListener('voiceschanged', () => {
                        console.log('üîä Voices loaded:', this.speechSynthesis.getVoices().length);
                    });
                }
            }

            async requestPermissions() {
                this.trackUserInteraction();
                try {
                    console.log('üé§ Requesting microphone permission...');
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    stream.getTracks().forEach(track => track.stop());
                    this.permissionsGranted = true;
                    console.log('‚úÖ Microphone permission granted');
                    await this.startGame();
                } catch (error) {
                    console.error('‚ùå Microphone permission denied:', error);
                    this.showError('Microphone permission is required. Please grant permission and try again.');
                }
            }

            async startGame() {
                try {
                    console.log('üéÆ Starting conversational game...');
                    await this.loadGameState();
                    this.renderConversationInterface();
                    await this.startConversation();
                } catch (error) {
                    console.error('Error starting game:', error);
                    this.showError('Failed to start game: ' + error.message);
                }
            }

            async loadGameState() {
                const response = await fetch('/api/game-state');
                if (!response.ok) throw new Error('Failed to load game state');
                this.gameState = await response.json();
                console.log('üìä Game state loaded:', this.gameState);
            }

            renderConversationInterface() {
                const container = document.getElementById('gameContainer');

                if (this.gameState.is_complete) {
                    this.renderGameComplete();
                    return;
                }

                container.innerHTML = `
                    <div class="conversation-card">
                        <div class="progress-section">
                            <div style="flex: 1;">
                                <div>Progress: ${this.gameState.progress.current}/${this.gameState.progress.total}</div>
                                <div class="progress-bar">
                                    <div class="progress-fill" style="width: ${(this.gameState.progress.current / this.gameState.progress.total) * 100}%"></div>
                                </div>
                            </div>
                            <div class="score-display">
                                Score: ${Math.round(this.gameState.score)}
                                ${this.gameState.streak > 1 ? `<br>üî• ${this.gameState.streak} streak!` : ''}
                            </div>
                        </div>

                        <div class="conversation-state" id="conversationState">
                            ü§ñ Preparing conversation...
                        </div>

                        <div class="figure-description">
                            <div>${this.gameState.current_figure.description}</div>
                        </div>

                        <!-- CONVERSATIONAL AUDIO SECTION -->
                        <div style="text-align: center; margin: 30px 0;">
                            <div style="font-size: 1.1rem; margin-bottom: 15px;" id="recordingStatus">
                                I'll ask the question, then automatically start listening for your answer!
                            </div>

                            <div class="audio-visualizer" id="audioVisualizer" style="display: none;">
                                ${Array(20).fill(0).map(() => '<div class="audio-bar"></div>').join('')}
                            </div>
                        </div>

                        <div id="debugPanel" class="debug-panel">
                            <div>Auto-Recording: <span id="recordingDebug">false</span></div>
                            <div>Audio Level: <span id="audioLevelDebug">0.000</span></div>
                            <div>Speech Detected: <span id="speechDebug">false</span></div>
                            <div>Silence Timer: <span id="timerDebug">inactive</span></div>
                            <div>Chunks Recorded: <span id="chunksDebug">0</span></div>
                        </div>

                        <div style="text-align: center; margin: 10px 0;">
                            <button class="conv-button" onclick="game.toggleDebug()" style="font-size: 0.8rem; padding: 8px 16px;">
                                üîç Toggle Debug
                            </button>
                            <button class="conv-button danger" onclick="game.manualStopRecording()" id="manualStopBtn" style="display: none;">
                                üõë Stop Recording
                            </button>
                        </div>

                        <div class="conversation-controls">
                            <button class="conv-button secondary" onclick="game.repeatQuestion()" id="repeatBtn" disabled>
                                üîÑ Repeat Question
                            </button>
                            <button class="conv-button" onclick="game.getHint()" id="hintBtn" disabled>
                                üí° Hint
                            </button>
                            <button class="conv-button danger" onclick="game.skipQuestion()" id="skipBtn" disabled>
                                ‚è≠Ô∏è Skip
                            </button>
                            <button class="conv-button primary" onclick="game.restartGame()" id="restartBtn">
                                üéÆ Restart
                            </button>
                        </div>

                        <div id="conversationResult" style="display: none;"></div>
                    </div>
                `;
            }

            async startConversation() {
                try {
                    console.log('üó£Ô∏è Starting conversation...');
                    const response = await fetch('/api/conversation/start', { method: 'POST' });
                    if (!response.ok) throw new Error('Failed to start conversation');
                    await this.speakQuestion();
                } catch (error) {
                    console.error('Error starting conversation:', error);
                    this.showError('Failed to start conversation: ' + error.message);
                }
            }

            async speakQuestion() {
                this.trackUserInteraction();
                const figure = this.gameState.current_figure;
                const questionText = `Here's your question: ${figure.description}. Who am I describing?`;

                this.updateConversationState('speaking', 'ü§ñ Speaking question...');

                await this.speak(questionText, () => {
                    // After question is spoken, AUTOMATICALLY start listening for voice answer
                    this.startAutoListening();
                });
            }

            speak(text, onComplete = null) {
                return new Promise((resolve) => {
                    console.log('üîä Speaking:', text.substring(0, 50) + '...');

                    if (this.isIOS) {
                        this.showSpeechText(text);
                        if (this.lastUserInteraction && (Date.now() - this.lastUserInteraction < 5000)) {
                            this.attemptSpeechSynthesis(text, onComplete, resolve);
                        } else {
                            setTimeout(() => {
                                this.hideSpeechText();
                                if (onComplete) onComplete();
                                resolve();
                            }, 3000);
                        }
                    } else {
                        this.attemptSpeechSynthesis(text, onComplete, resolve);
                    }
                });
            }

            attemptSpeechSynthesis(text, onComplete, resolve) {
                try {
                    this.speechSynthesis.cancel();
                    const utterance = new SpeechSynthesisUtterance(text);

                    const voices = this.speechSynthesis.getVoices();
                    const preferredVoice = voices.find(voice =>
                        voice.lang.includes('en') && voice.name.includes('Female')
                    ) || voices.find(voice => voice.lang.includes('en')) || voices[0];

                    if (preferredVoice) utterance.voice = preferredVoice;
                    utterance.rate = 0.9;
                    utterance.pitch = 1.0;
                    utterance.volume = 0.8;

                    utterance.onend = () => {
                        console.log('üîä Speech complete');
                        this.hideSpeechText();
                        if (onComplete) onComplete();
                        resolve();
                    };

                    utterance.onerror = (error) => {
                        console.error('üîä Speech error:', error);
                        this.hideSpeechText();
                        if (onComplete) onComplete();
                        resolve();
                    };

                    this.currentUtterance = utterance;
                    this.speechSynthesis.speak(utterance);

                    setTimeout(() => {
                        if (this.currentUtterance === utterance) {
                            console.log('‚è∞ Speech timeout');
                            this.hideSpeechText();
                            if (onComplete) onComplete();
                            resolve();
                        }
                    }, 8000);

                } catch (error) {
                    console.error('‚ùå Speech synthesis failed:', error);
                    this.hideSpeechText();
                    if (onComplete) onComplete();
                    resolve();
                }
            }

            showSpeechText(text) {
                this.hideSpeechText();
                const speechDisplay = document.createElement('div');
                speechDisplay.id = 'speechTextDisplay';
                speechDisplay.className = 'speech-text-display';
                speechDisplay.innerHTML = `
                    <div style="display: flex; justify-content: space-between; align-items: start;">
                        <div>ü§ñ <strong>AI Tutor:</strong> ${text}</div>
                        <button onclick="game.hideSpeechText()" style="background: rgba(255,255,255,0.2); border: none; color: white; border-radius: 5px; padding: 5px 10px; cursor: pointer; margin-left: 10px;">‚úï</button>
                    </div>
                `;
                document.body.appendChild(speechDisplay);
            }

            hideSpeechText() {
                const existing = document.getElementById('speechTextDisplay');
                if (existing) existing.remove();
            }

            // AUTO-START LISTENING AFTER QUESTION (CONVERSATIONAL FLOW)
            async startAutoListening() {
                if (!this.permissionsGranted) {
                    await this.requestPermissions();
                    return;
                }

                try {
                    console.log('üëÇ Auto-starting voice listening...');
                    this.updateConversationState('listening', 'üëÇ Listening for your voice answer...');

                    // Enable controls
                    this.enableControls(['repeatBtn', 'hintBtn', 'skipBtn']);

                    // Show manual stop button
                    const manualStop = document.getElementById('manualStopBtn');
                    if (manualStop) manualStop.style.display = 'inline-block';

                    const status = document.getElementById('recordingStatus');
                    if (status) status.textContent = 'Listening... speak your answer! (Auto-stops after 3.5s silence, min 2s recording)';

                    // START RECORDING AUTOMATICALLY USING INDEX.HTML LOGIC
                    await this.startRecordingAuto();

                } catch (error) {
                    console.error('Error starting auto-listening:', error);
                    this.showError('Failed to start listening: ' + error.message);
                }
            }

            // EXACT COPY of startRecording() from index.html - just auto-triggered
            async startRecordingAuto() {
                try {
                    console.log('üé§ Starting auto-recording using EXACT index.html logic...');

                    // EXACT STREAM SETUP FROM INDEX.HTML
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    this.setupAudioVisualization(stream);

                    // EXACT MEDIA RECORDER SETUP FROM INDEX.HTML
                    const options = { mimeType: 'audio/webm;codecs=opus' };
                    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                        options.mimeType = 'audio/webm';
                    }
                    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                        options.mimeType = 'audio/mp4';
                    }
                    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                        delete options.mimeType;
                    }

                    this.mediaRecorder = new MediaRecorder(stream, options);
                    this.audioChunks = [];

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                        }
                    };

                    this.mediaRecorder.onstop = () => {
                        this.processAudio();
                    };

                    this.mediaRecorder.start(100);
                    this.isRecording = true;

                    const visualizer = document.getElementById('audioVisualizer');
                    if (visualizer) visualizer.style.display = 'flex';

                    // ONLY ADDITION: Simple timeout for auto-stop (no complex VAD)
                    setTimeout(() => {
                        if (this.isRecording) {
                            console.log('üõë Auto-stopping after 8 seconds');
                            this.stopRecordingAuto();
                        }
                    }, 8000); // Just 8 second timeout, no complex detection

                    console.log('‚úÖ Auto-recording started using index.html logic');

                } catch (error) {
                    console.error('Error starting auto-recording:', error);
                    throw error;
                }
            }

            // EXACT COPY of setupAudioVisualization from index.html
            setupAudioVisualization(stream) {
                try {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);
                    this.analyser.fftSize = 64;
                    const bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(bufferLength);
                    this.animateVisualizer();
                } catch (error) {
                    console.log('Audio visualization not supported:', error);
                }
            }

            // EXACT COPY of animateVisualizer from index.html
            animateVisualizer() {
                if (!this.isRecording || !this.analyser) return;
                requestAnimationFrame(() => this.animateVisualizer());
                this.analyser.getByteFrequencyData(this.dataArray);
                const bars = document.querySelectorAll('.audio-bar');
                bars.forEach((bar, index) => {
                    const value = this.dataArray[index] || 0;
                    const height = (value / 255) * 100;
                    bar.style.height = `${Math.max(5, height)}%`;
                    bar.classList.toggle('active', value > 30);
                });
            }

            // Remove the complex VAD timer
            startAutoStopTimer() {
                // No complex VAD - just use simple timeout in startRecordingAuto
                console.log('üîÑ Using simple 8-second timeout instead of complex VAD');
            }

            updateDebugInfo(audioLevel, isSpeech, recordingDuration, maxValue, activeCount) {
                const debugPanel = document.getElementById('debugPanel');
                if (!debugPanel || debugPanel.style.display === 'none') return;

                const silenceDuration = this.silenceStartTime ? Date.now() - this.silenceStartTime : 0;
                const minRecordingMet = recordingDuration >= 2000;

                let timerStatus = 'waiting for speech';
                if (this.speechDetected) {
                    if (this.silenceStartTime) {
                        timerStatus = `${(silenceDuration/1000).toFixed(1)}s silence (need 3.5s)`;
                    } else {
                        timerStatus = 'speech active';
                    }
                } else if (recordingDuration < 2000) {
                    timerStatus = `warming up (${(recordingDuration/1000).toFixed(1)}s)`;
                }

                document.getElementById('recordingDebug').textContent = `${this.isRecording} (${(recordingDuration/1000).toFixed(1)}s)`;
                document.getElementById('audioLevelDebug').textContent = `max:${maxValue} active:${activeCount}`;
                document.getElementById('speechDebug').textContent = `${isSpeech} detected:${this.speechDetected}`;
                document.getElementById('timerDebug').textContent = timerStatus;
                document.getElementById('chunksDebug').textContent = this.audioChunks ? this.audioChunks.length : 0;
            }

            manualStopRecording() {
                console.log('üõë Manual stop requested');
                if (this.vadTimer) {
                    clearInterval(this.vadTimer);
                    this.vadTimer = null;
                }
                this.stopRecordingAuto();
            }

            async stopRecordingAuto() {
                if (this.mediaRecorder && this.isRecording) {
                    console.log('üõë Stopping auto-recording...');

                    if (this.vadTimer) {
                        clearInterval(this.vadTimer);
                        this.vadTimer = null;
                    }

                    this.mediaRecorder.stop();
                    this.mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    this.isRecording = false;

                    const status = document.getElementById('recordingStatus');
                    const visualizer = document.getElementById('audioVisualizer');
                    const manualStop = document.getElementById('manualStopBtn');

                    if (status) status.textContent = 'Processing your answer...';
                    if (visualizer) visualizer.style.display = 'none';
                    if (manualStop) manualStop.style.display = 'none';

                    this.updateConversationState('processing', 'üß† Processing your answer...');
                    this.disableControls(['repeatBtn', 'hintBtn', 'skipBtn']);
                    this.isProcessing = true;
                }
            }

            // EXACT AUDIO PROCESSING FROM INDEX.HTML
            async processAudio() {
                try {
                    console.log('üé¨ Processing audio... Chunks:', this.audioChunks.length);

                    if (this.audioChunks.length === 0) {
                        throw new Error('No audio recorded. Please try speaking louder.');
                    }

                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    console.log('üì¶ Audio blob size:', audioBlob.size, 'bytes');

                    if (audioBlob.size < 1000) {
                        throw new Error('Recording too short. Please try speaking for longer.');
                    }

                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'recording.webm');

                    // USE CONVERSATIONAL ENDPOINT (WHICH IS SAME AS MANUAL)
                    console.log('üì§ Submitting to /api/conversation/submit-answer');
                    const response = await fetch('/api/conversation/submit-answer', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || 'Server error');
                    }

                    const result = await response.json();
                    console.log('‚úÖ Answer processed successfully:', result);

                    await this.showResult(result);

                } catch (error) {
                    console.error('‚ùå Error processing audio:', error);
                    this.showError('Error processing answer: ' + error.message);
                    // Restart listening after error
                    setTimeout(() => this.startAutoListening(), 2000);
                } finally {
                    this.isProcessing = false;
                }
            }

            async showResult(result) {
                const resultDiv = document.getElementById('conversationResult');
                const analysis = result.analysis || {};

                resultDiv.innerHTML = `
                    <div class="conversation-result">
                        <div class="result-score">Score: ${Math.round(analysis.overall_score || 0)}/100</div>
                        <div style="font-style: italic; margin: 10px 0;">
                            <strong>You said:</strong> "${result.transcription || 'No speech detected'}"
                        </div>
                        <div style="margin: 10px 0;">
                            <strong>Correct answer:</strong> ${result.figure_name || 'Unknown'}
                        </div>
                    </div>
                `;
                resultDiv.style.display = 'block';

                const feedbackText = this.generateFeedback(result);
                this.updateConversationState('speaking', 'ü§ñ Providing feedback...');

                await this.speak(feedbackText, () => {
                    this.waitForNext(result);
                });
            }

            generateFeedback(result) {
                const accuracy = result.analysis?.accuracy_score || 0;
                const transcription = result.transcription || '';
                const figureName = result.figure_name || 'the figure';

                if (accuracy >= 90) {
                    return `Perfect! You said "${transcription}" and that's exactly right!`;
                } else if (accuracy >= 70) {
                    return `Correct! You said "${transcription}" - that's ${figureName}!`;
                } else if (accuracy >= 40) {
                    return `Close! You said "${transcription}" - I was looking for ${figureName}.`;
                } else {
                    return `Not quite. You said "${transcription}", but the answer was ${figureName}.`;
                }
            }

            waitForNext(result) {
                this.updateConversationState('waiting', '‚è≥ Say "next" to continue...');

                if (result.is_final_figure) {
                    this.speak('Congratulations! Say "next" to see your final results.');
                } else {
                    this.speak('Say "next" when ready for the next question.');
                }

                setTimeout(() => {
                    this.showManualNext();
                    this.startSimpleCommandListener();
                }, 2000);
            }

            async startSimpleCommandListener() {
                // Simple voice command listening for "next"
                if (!this.permissionsGranted || this.conversationState !== 'waiting') return;

                try {
                    console.log('üëÇ Listening for "next" command...');
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                    const recorder = new MediaRecorder(stream);
                    const chunks = [];

                    recorder.ondataavailable = (event) => {
                        if (event.data.size > 0) chunks.push(event.data);
                    };

                    recorder.onstop = async () => {
                        stream.getTracks().forEach(track => track.stop());
                        if (chunks.length === 0 || this.conversationState !== 'waiting') return;

                        const audioBlob = new Blob(chunks);
                        if (audioBlob.size < 500) return;

                        const formData = new FormData();
                        formData.append('audio', audioBlob, 'command.webm');

                        try {
                            const response = await fetch('/api/conversation/voice-command-audio', {
                                method: 'POST',
                                body: formData
                            });

                            if (response.ok) {
                                const result = await response.json();
                                const transcript = result.transcription?.toLowerCase() || '';
                                console.log('üéôÔ∏è Command transcribed:', transcript);

                                if (transcript.includes('next')) {
                                    console.log('‚úÖ "Next" command detected!');
                                    this.updateConversationState('processing', '‚úÖ "Next" detected!');
                                    setTimeout(() => this.nextQuestion(), 500);
                                    return;
                                }
                            }
                        } catch (error) {
                            console.log('‚ö†Ô∏è Command error:', error);
                        }

                        // Continue listening if still waiting
                        if (this.conversationState === 'waiting') {
                            setTimeout(() => this.startSimpleCommandListener(), 1000);
                        }
                    };

                    recorder.start();
                    setTimeout(() => {
                        if (recorder.state === 'recording') recorder.stop();
                    }, 3000);

                } catch (error) {
                    console.error('‚ùå Command listener error:', error);
                }
            }

            showManualNext() {
                const controls = document.querySelector('.conversation-controls');
                if (document.getElementById('nextQuestionBtn')) return;

                const nextButton = document.createElement('button');
                nextButton.className = 'conv-button primary';
                nextButton.id = 'nextQuestionBtn';
                nextButton.onclick = () => this.nextQuestion();
                nextButton.innerHTML = '‚û°Ô∏è Next Question';
                controls.appendChild(nextButton);
            }

            async nextQuestion() {
                this.trackUserInteraction();
                console.log('‚û°Ô∏è Moving to next question...');

                const nextBtn = document.getElementById('nextQuestionBtn');
                if (nextBtn) nextBtn.remove();

                this.conversationState = 'idle';
                const status = document.getElementById('recordingStatus');
                if (status) status.textContent = 'Preparing next question...';

                await this.loadGameState();

                if (this.gameState.is_complete) {
                    this.renderGameComplete();
                } else {
                    this.renderConversationInterface();
                    await this.startConversation();
                }
            }

            updateConversationState(state, text) {
                const stateElement = document.getElementById('conversationState');
                if (stateElement) {
                    stateElement.className = `conversation-state state-${state}`;
                    stateElement.textContent = text;
                }
                this.conversationState = state;
            }

            enableControls(controlIds) {
                controlIds.forEach(id => {
                    const element = document.getElementById(id);
                    if (element) element.disabled = false;
                });
            }

            disableControls(controlIds) {
                controlIds.forEach(id => {
                    const element = document.getElementById(id);
                    if (element) element.disabled = true;
                });
            }

            toggleDebug() {
                const debugPanel = document.getElementById('debugPanel');
                if (debugPanel) {
                    debugPanel.style.display = debugPanel.style.display === 'none' ? 'block' : 'none';
                }
            }

            async repeatQuestion() {
                this.trackUserInteraction();
                await this.speakQuestion();
            }

            async getHint() {
                this.trackUserInteraction();
                const figure = this.gameState.current_figure;
                const hintText = `Here's a hint: ${figure.hint}`;
                await this.speak(hintText);
            }

            async skipQuestion() {
                this.trackUserInteraction();
                const figure = this.gameState.current_figure;
                const skipText = `No problem! The answer was ${figure.name}.`;
                await this.speak(skipText, () => {
                    this.waitForNext({ is_final_figure: false });
                });
            }

            async restartGame() {
                this.trackUserInteraction();
                try {
                    const response = await fetch('/api/restart-game', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ mode: 'classic' })
                    });
                    if (response.ok) location.reload();
                } catch (error) {
                    console.error('Error restarting:', error);
                }
            }

            renderGameComplete() {
                const container = document.getElementById('gameContainer');
                container.innerHTML = `
                    <div class="conversation-card">
                        <h2 style="text-align: center; margin-bottom: 20px;">üéâ Congratulations!</h2>
                        <p style="text-align: center; font-size: 1.2rem;">You've completed all the historical figures!</p>
                        <div style="text-align: center; margin-top: 30px;">
                            <button class="conv-button primary" onclick="game.restartGame()">
                                üéÆ Start New Game
                            </button>
                        </div>
                    </div>
                `;
            }

            showError(message) {
                const container = document.getElementById('gameContainer');
                container.innerHTML = `
                    <div class="conversation-card">
                        <div class="error-message">${message}</div>
                        <div style="text-align: center; margin-top: 20px;">
                            <button class="conv-button primary" onclick="location.reload()">üîÑ Retry</button>
                        </div>
                    </div>
                `;
            }
        }

        // Global functions
        let game;

        function setMode(mode) {
            document.getElementById('manualMode').classList.toggle('active', mode === 'manual');
            document.getElementById('conversationalMode').classList.toggle('active', mode === 'conversational');

            if (mode === 'manual') {
                window.location.href = '/';
            } else {
                if (!game) {
                    game = new ConversationalHistoryGame();
                }
            }
        }

        window.addEventListener('load', () => {
            game = new ConversationalHistoryGame();
        });
    </script>
</body>
</html>