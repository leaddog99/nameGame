<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Conversational Historical Figures Game</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
            overflow-x: hidden;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
        }
        .header {
            text-align: center;
            margin-bottom: 30px;
            animation: slideInDown 0.8s ease-out;
        }
        .title {
            font-size: 2.5rem;
            font-weight: bold;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
            margin-bottom: 10px;
        }
        .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }
        .conversation-card {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            margin: 20px 0;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            animation: slideInUp 0.8s ease-out;
            transition: all 0.3s ease;
        }

        /* Conversation States */
        .conversation-state {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 20px;
            padding: 15px;
            border-radius: 15px;
            font-weight: bold;
            font-size: 1.1rem;
            transition: all 0.3s ease;
        }
        .state-speaking {
            background: rgba(76, 175, 80, 0.2);
            border: 2px solid rgba(76, 175, 80, 0.5);
            animation: speakingPulse 2s infinite;
        }
        .state-listening {
            background: rgba(33, 150, 243, 0.2);
            border: 2px solid rgba(33, 150, 243, 0.5);
            animation: listeningPulse 1.5s infinite;
        }
        .state-processing {
            background: rgba(156, 39, 176, 0.2);
            border: 2px solid rgba(156, 39, 176, 0.5);
            animation: processingPulse 1s infinite;
        }
        .state-waiting {
            background: rgba(255, 193, 7, 0.2);
            border: 2px solid rgba(255, 193, 7, 0.5);
            animation: waitingPulse 2.5s infinite;
        }

        @keyframes speakingPulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.8; transform: scale(1.05); }
        }
        @keyframes listeningPulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        @keyframes processingPulse {
            0%, 100% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        @keyframes waitingPulse {
            0%, 100% { opacity: 1; }
            25%, 75% { opacity: 0.6; }
        }

        /* Voice Visualizer */
        .voice-visualizer {
            display: flex;
            justify-content: center;
            align-items: flex-end;
            height: 80px;
            margin: 20px 0;
            gap: 3px;
            border-radius: 10px;
            background: rgba(0, 0, 0, 0.1);
            padding: 10px;
        }
        .voice-bar {
            width: 6px;
            background: linear-gradient(to top, #4CAF50, #81C784);
            border-radius: 3px;
            transition: height 0.1s ease;
            min-height: 4px;
        }
        .voice-bar.active {
            background: linear-gradient(to top, #FF6B6B, #FF8E53);
            animation: voiceWave 0.3s ease-in-out infinite alternate;
        }
        @keyframes voiceWave {
            0% { opacity: 0.7; }
            100% { opacity: 1; }
        }

        /* Progress and Score */
        .progress-section {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 25px;
            flex-wrap: wrap;
            gap: 15px;
        }
        .progress-bar {
            flex: 1;
            height: 12px;
            background: rgba(255,255,255,0.2);
            border-radius: 6px;
            overflow: hidden;
            min-width: 200px;
        }
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #45a049);
            border-radius: 6px;
            transition: width 0.8s ease;
        }
        .score-display {
            font-size: 1.3rem;
            font-weight: bold;
            text-align: right;
        }

        /* Figure Description */
        .figure-description {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            margin-bottom: 25px;
            border-left: 4px solid #FFD700;
        }

        /* Conversation Controls */
        .conversation-controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .conv-button {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 24px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 1rem;
            font-weight: bold;
        }
        .conv-button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        .conv-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        .conv-button.primary {
            background: linear-gradient(135deg, #4CAF50, #45a049);
        }
        .conv-button.secondary {
            background: linear-gradient(135deg, #FF9800, #F57C00);
        }
        .conv-button.danger {
            background: linear-gradient(135deg, #F44336, #D32F2F);
        }

        /* Speaking Indicator */
        .speaking-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px 0;
            font-size: 1.2rem;
            font-weight: bold;
        }
        .speaking-icon {
            animation: speakingIcon 1s infinite;
            margin-right: 10px;
        }
        @keyframes speakingIcon {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.2); }
        }

        /* Results Display */
        .conversation-result {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            margin: 15px 0;
            animation: slideInUp 0.6s ease-out;
        }
        .result-score {
            font-size: 1.5rem;
            font-weight: bold;
            text-align: center;
            margin-bottom: 15px;
        }
        .result-feedback {
            font-style: italic;
            text-align: center;
            margin: 10px 0;
        }

        /* Error Messages */
        .error-message {
            background: rgba(244, 67, 54, 0.2);
            border: 1px solid rgba(244, 67, 54, 0.5);
            color: #ff6b6b;
            padding: 15px;
            border-radius: 10px;
            margin: 15px 0;
            text-align: center;
            animation: shake 0.5s ease-in-out;
        }
        @keyframes shake {
            0%, 100% { transform: translateX(0); }
            25% { transform: translateX(-5px); }
            75% { transform: translateX(5px); }
        }

        /* Permission Request */
        .permission-request {
            text-align: center;
            padding: 30px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            margin: 20px 0;
        }

        /* Mode Toggle */
        .mode-toggle {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-bottom: 20px;
        }
        .mode-button {
            padding: 10px 20px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border-radius: 20px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .mode-button.active {
            background: rgba(255, 255, 255, 0.3);
            border-color: rgba(255, 255, 255, 0.6);
        }

        @keyframes slideInDown {
            from { opacity: 0; transform: translateY(-50px); }
            to { opacity: 1; transform: translateY(0); }
        }
        @keyframes slideInUp {
            from { opacity: 0; transform: translateY(50px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @media (max-width: 768px) {
            .container { padding: 15px; }
            .title { font-size: 2rem; }
            .conversation-card { padding: 20px; }
            .conversation-controls { flex-direction: column; }
            .conv-button { width: 100%; }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="title">üéôÔ∏è Conversational History Game</h1>
            <p class="subtitle">Speak naturally with your AI tutor about historical figures!</p>
        </div>

        <div class="mode-toggle">
            <button class="mode-button" id="manualMode" onclick="setMode('manual')">Manual Mode</button>
            <button class="mode-button active" id="conversationalMode" onclick="setMode('conversational')">Conversational Mode</button>
        </div>

        <div id="gameContainer">
            <div class="conversation-card">
                <div class="permission-request">
                    <h3>üé§ Microphone Permission Required</h3>
                    <p>This conversational mode needs microphone access to hear your responses.</p>
                    <button class="conv-button primary" onclick="game.requestPermissions()">Grant Permission & Start</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        class ConversationalHistoryGame {
            constructor() {
                this.gameMode = 'conversational';
                this.conversationState = 'idle';
                this.gameState = null;
                this.mediaRecorder = null;
                this.audioContext = null;
                this.analyser = null;
                this.isRecording = false;
                this.speechSynthesis = null;
                this.vadConfig = null;
                this.permissionsGranted = false;

                // Voice Activity Detection
                this.isListening = false;
                this.speechDetected = false;
                this.silenceStartTime = null;
                this.speechStartTime = null;
                this.audioLevelHistory = [];

                // FIXED: Add frame counter for visualizer debugging
                this.frameCounter = 0;

                // FIXED: Add final stats storage and auto-advance timer
                this.finalStats = null;
                this.autoAdvanceTimer = null;

                // TTS Management
                this.currentUtterance = null;
                this.speechQueue = [];

                this.init();
            }

            async init() {
                this.setupSpeechSynthesis();
                this.checkBrowserSupport();
            }

            checkBrowserSupport() {
                const errors = [];

                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    errors.push("Microphone access not supported");
                }

                if (!window.SpeechSynthesisUtterance) {
                    errors.push("Text-to-speech not supported");
                }

                if (!window.AudioContext && !window.webkitAudioContext) {
                    errors.push("Web Audio API not supported");
                }

                if (errors.length > 0) {
                    this.showError("Browser not supported: " + errors.join(", "));
                    return false;
                }

                return true;
            }

            setupSpeechSynthesis() {
                this.speechSynthesis = window.speechSynthesis;

                // Wait for voices to load
                if (this.speechSynthesis.getVoices().length === 0) {
                    this.speechSynthesis.addEventListener('voiceschanged', () => {
                        console.log('üîä Voices loaded:', this.speechSynthesis.getVoices().length);
                    });
                }
            }

            async requestPermissions() {
    try {
        console.log('üé§ Requesting microphone permission...');

        // ü©π iOS Safari audio playback fix
        document.addEventListener('touchstart', () => {
            try {
                const utterance = new SpeechSynthesisUtterance('');
                speechSynthesis.speak(utterance);
                speechSynthesis.cancel(); // Cancel dummy utterance
            } catch (e) {
                console.warn("iOS speechSynthesis preload failed:", e);
            }

            if (window.audioContext && window.audioContext.state === 'suspended') {
                window.audioContext.resume().then(() => {
                    console.log("‚úÖ AudioContext resumed");
                });
            }
        }, { once: true });

        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            }
        });

        stream.getTracks().forEach(track => track.stop());

        this.permissionsGranted = true;
        console.log('‚úÖ Microphone permission granted');

        await this.startGame();

    } catch (error) {
        console.error('‚ùå Microphone permission denied:', error);
        this.showError('Microphone permission is required for conversational mode. Please grant permission and try again.');
    }
}


            async startGame() {
                try {
                    console.log('üéÆ Starting conversational game...');

                    // Load game state
                    await this.loadGameState();

                    // Get VAD configuration
                    await this.loadVADConfig();

                    // Render conversation interface
                    this.renderConversationInterface();

                    // Start the conversation
                    await this.startConversation();

                } catch (error) {
                    console.error('Error starting game:', error);
                    this.showError('Failed to start game: ' + error.message);
                }
            }

            async loadGameState() {
                const response = await fetch('/api/game-state');
                if (!response.ok) throw new Error('Failed to load game state');
                this.gameState = await response.json();
                console.log('üìä Game state loaded:', this.gameState);
            }

            async loadVADConfig() {
                try {
                    const response = await fetch('/api/conversation/voice-activity-config');
                    if (!response.ok) throw new Error('Failed to load VAD config');
                    const data = await response.json();
                    this.vadConfig = data.vad_config;
                    console.log('üéôÔ∏è VAD config loaded successfully:', this.vadConfig);

                    // Use simple fallback if config missing
                    if (!this.vadConfig || !this.vadConfig.timing) {
                        console.warn('‚ö†Ô∏è Invalid VAD config, using defaults');
                        this.vadConfig = {
                            timing: {
                                silence_duration_ms: 2000,
                                max_recording_duration_ms: 30000
                            }
                        };
                    }
                } catch (error) {
                    console.error('‚ùå Failed to load VAD config:', error);
                    // Use fallback config
                    this.vadConfig = {
                        timing: {
                            silence_duration_ms: 2000,
                            max_recording_duration_ms: 30000
                        }
                    };
                    console.log('üîß Using fallback VAD config:', this.vadConfig);
                }
            }

            renderConversationInterface() {
                const container = document.getElementById('gameContainer');

                if (this.gameState.is_complete) {
                    this.renderGameComplete();
                    return;
                }

                container.innerHTML = `
                    <div class="conversation-card">
                        <div class="progress-section">
                            <div style="flex: 1;">
                                <div>Progress: ${this.gameState.progress.current}/${this.gameState.progress.total}</div>
                                <div class="progress-bar">
                                    <div class="progress-fill" style="width: ${(this.gameState.progress.current / this.gameState.progress.total) * 100}%"></div>
                                </div>
                            </div>
                            <div class="score-display">
                                Score: ${Math.round(this.gameState.score)}
                                ${this.gameState.streak > 1 ? `<br>üî• ${this.gameState.streak} streak!` : ''}
                            </div>
                        </div>

                        <div class="conversation-state" id="conversationState">
                            ü§ñ Preparing conversation...
                        </div>

                        <div class="figure-description" id="figureDescription" style="display: none;">
                            <div id="descriptionText"></div>
                        </div>

                        <div class="voice-visualizer" id="voiceVisualizer">
                            ${Array(25).fill(0).map(() => '<div class="voice-bar"></div>').join('')}
                        </div>

                        <div id="debugPanel" style="background: rgba(0,0,0,0.2); padding: 10px; border-radius: 10px; font-family: monospace; font-size: 0.8rem; margin: 10px 0; display: none;">
                            <div>Audio Level: <span id="audioLevelDebug">0.000</span></div>
                            <div>Speech Threshold: <span id="thresholdDebug">0.150</span></div>
                            <div>Speech Detected: <span id="speechDebug">false</span></div>
                            <div>Silence Duration: <span id="silenceDebug">0ms</span></div>
                            <div>Recording State: <span id="recordingStateDebug">inactive</span></div>
                            <div>Audio Chunks: <span id="audioChunksDebug">0</span></div>
                            <div>Is Listening: <span id="isListeningDebug">false</span></div>
                            <div>Visualizer Activity: <span id="visualizerDebug">none</span></div>
                            <div style="margin-top: 5px; font-size: 0.7rem; color: #ccc;">
                                FIXED: Enhanced debugging for voice detection & visualizer
                            </div>
                        </div>

                        <div style="text-align: center; margin: 10px 0;">
                            <button class="conv-button" onclick="game.toggleDebug()" style="font-size: 0.8rem; padding: 8px 16px;">
                                üîç Toggle Debug
                            </button>
                            <button class="conv-button" onclick="game.forceStartListening()" style="font-size: 0.8rem; padding: 8px 16px; margin-left: 10px;">
                                üé§ Force Listen
                            </button>
                        </div>

                        <div class="conversation-controls">
                            <button class="conv-button danger" onclick="game.pauseConversation()" id="pauseBtn">
                                ‚è∏Ô∏è Pause
                            </button>
                            <button class="conv-button danger" onclick="game.exitConversation()" id="exitBtn">
                                üö™ Exit
                            </button>
                            <button class="conv-button" onclick="game.stopRecording()" id="stopRecordingBtn" style="display: none;">
                                üõë Stop Recording
                            </button>
                            <button class="conv-button secondary" onclick="game.repeatQuestion()" id="repeatBtn" disabled>
                                üîÑ Repeat Question
                            </button>
                            <button class="conv-button" onclick="game.getHint()" id="hintBtn" disabled>
                                üí° Hint
                            </button>
                            <button class="conv-button danger" onclick="game.skipQuestion()" id="skipBtn" disabled>
                                ‚è≠Ô∏è Skip
                            </button>
                            <button class="conv-button primary" onclick="game.restartGame()" id="restartBtn">
                                üéÆ Restart
                            </button>
                        </div>

                        <div id="conversationResult" style="display: none;"></div>
                    </div>
                `;
            }

            async startConversation() {
                try {
                    console.log('üó£Ô∏è Starting conversation for current figure...');

                    const response = await fetch('/api/conversation/start', { method: 'POST' });
                    if (!response.ok) throw new Error('Failed to start conversation');

                    const result = await response.json();
                    console.log('‚úÖ Conversation started:', result);

                    // The backend has started the conversation
                    // Now we need to speak the question
                    await this.speakQuestion();

                } catch (error) {
                    console.error('Error starting conversation:', error);
                    this.showError('Failed to start conversation: ' + error.message);
                }
            }

            async speakQuestion() {
                const figure = this.gameState.current_figure;
                const questionText = `Here's your question: ${figure.description}. Who am I describing?`;

                this.updateConversationState('speaking', 'ü§ñ Speaking question...');

                await this.speak(questionText, () => {
                    // After question is spoken, start listening
                    this.startListening();
                });
            }

            speak(text, onComplete = null) {
                return new Promise((resolve) => {
                    // Stop any current speech
                    this.speechSynthesis.cancel();

                    const utterance = new SpeechSynthesisUtterance(text);

                    // Configure voice settings - PREFER FEMALE VOICES
                    const voices = this.speechSynthesis.getVoices();

                    // FIXED: Better female voice selection
                    const preferredVoice = voices.find(voice =>
                        voice.lang.includes('en') &&
                        (voice.name.toLowerCase().includes('female') ||
                         voice.name.toLowerCase().includes('zira') ||
                         voice.name.toLowerCase().includes('samantha') ||
                         voice.name.toLowerCase().includes('karen') ||
                         voice.name.toLowerCase().includes('susan'))
                    ) || voices.find(voice => voice.lang.includes('en')) || voices[0];

                    if (preferredVoice) {
                        utterance.voice = preferredVoice;
                        console.log('üé≠ Using voice:', preferredVoice.name);
                    }

                    utterance.rate = 0.9;
                    utterance.pitch = 1.0;
                    utterance.volume = 0.8;

                    utterance.onend = () => {
                        console.log('üîä Speech synthesis complete');
                        if (onComplete) onComplete();
                        resolve();
                    };

                    utterance.onerror = (error) => {
                        console.error('üîä Speech synthesis error:', error);
                        if (onComplete) onComplete();
                        resolve();
                    };

                    this.currentUtterance = utterance;
                    this.speechSynthesis.speak(utterance);

                    console.log('üîä Speaking:', text.substring(0, 50) + '...');
                });
            }

            async startListening() {
                if (!this.permissionsGranted) {
                    await this.requestPermissions();
                    return;
                }

                try {
                    console.log('üëÇ Starting to listen...');

                    this.updateConversationState('listening', 'üëÇ Listening for your answer...');
                    this.enableControls(['repeatBtn', 'hintBtn', 'skipBtn', 'stopRecordingBtn']);

                    // Show the manual stop button
                    const stopBtn = document.getElementById('stopRecordingBtn');
                    if (stopBtn) stopBtn.style.display = 'inline-block';

                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: 16000
                        }
                    });

                    // FIXED: Set up audio analysis FIRST, then recording
                    this.setupSimpleAudioAnalysis(stream);
                    this.setupRecording(stream);

                    // FIXED: Force start the audio analysis loop
                    console.log('üîß FORCE STARTING audio analysis loop...');
                    setTimeout(() => {
                        if (this.isListening && this.analyser) {
                            console.log('‚úÖ Starting audio analysis loop');
                            this.analyzeAudioEnhanced();
                        } else {
                            console.error('‚ùå Cannot start audio analysis - isListening:', this.isListening, 'analyser:', !!this.analyser);
                        }
                    }, 100);

                    // START RECORDING IMMEDIATELY - don't wait for speech detection
                    console.log('üìπ Starting MediaRecorder immediately...');
                    try {
                        this.mediaRecorder.start(100);
                        this.isRecording = true;
                        console.log('‚úÖ MediaRecorder started successfully');
                    } catch (error) {
                        console.error('‚ùå Failed to start MediaRecorder:', error);
                        throw error;
                    }

                    this.isListening = true;
                    this.speechDetected = false;
                    this.silenceStartTime = null;
                    this.speechStartTime = null;

                    console.log('‚úÖ Listening started successfully');

                } catch (error) {
                    console.error('Error starting to listen:', error);
                    this.showError('Failed to access microphone: ' + error.message);
                }
            }

            stopRecording() {
                console.log('üõë Manual stop recording requested');
                this.stopListening();
            }

            // FIXED: Renamed and simplified audio analysis
            setupSimpleAudioAnalysis(stream) {
                try {
                    console.log('üîä SETTING UP SIMPLE AUDIO ANALYSIS...');
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();

                    const source = this.audioContext.createMediaStreamSource(stream);
                    source.connect(this.analyser);

                    // FIXED: Better settings for both detection and visualization
                    this.analyser.fftSize = 256;
                    this.analyser.smoothingTimeConstant = 0.3;  // Less smoothing for responsiveness

                    const bufferLength = this.analyser.frequencyBinCount;
                    this.dataArray = new Uint8Array(bufferLength);        // For visualizer
                    this.timeDataArray = new Uint8Array(this.analyser.fftSize);    // For voice detection

                    console.log('‚úÖ SIMPLE AUDIO ANALYSIS SETUP COMPLETE!');
                    console.log('üìä FFT Size:', this.analyser.fftSize, 'Frequency Bins:', bufferLength);
                    console.log('üéôÔ∏è Stream tracks:', stream.getTracks().length);

                    // FIXED: Test that we can get data immediately
                    this.analyser.getByteFrequencyData(this.dataArray);
                    this.analyser.getByteTimeDomainData(this.timeDataArray);
                    console.log('üß™ Initial data test - Freq max:', Math.max(...this.dataArray), 'Time sample:', this.timeDataArray[0]);

                } catch (error) {
                    console.error('‚ùå Error setting up simple audio analysis:', error);
                    this.showError('Failed to setup audio analysis: ' + error.message);
                }
            }

            setupRecording(stream) {
                try {
                    console.log('üé¨ Setting up MediaRecorder...');

                    // Try WAV first (no conversion needed), then WebM fallbacks
                    const options = { mimeType: 'audio/wav' };
                    if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                        console.log('‚ö†Ô∏è WAV not supported, trying webm...');
                        options.mimeType = 'audio/webm;codecs=opus';
                        if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                            console.log('‚ö†Ô∏è Opus not supported, trying webm...');
                            options.mimeType = 'audio/webm';
                            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                                console.log('‚ö†Ô∏è WebM not supported, trying mp4...');
                                options.mimeType = 'audio/mp4';
                                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                                    console.log('‚ö†Ô∏è MP4 not supported, using default...');
                                    delete options.mimeType;
                                }
                            }
                        }
                    }

                    console.log('üéØ Using MIME type:', options.mimeType || 'default');

                    this.mediaRecorder = new MediaRecorder(stream, options);
                    this.audioChunks = [];
                    this.currentMimeType = options.mimeType || 'audio/webm';

                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            this.audioChunks.push(event.data);
                            console.log('üì¶ Audio chunk received:', event.data.size, 'bytes, total chunks:', this.audioChunks.length);
                        }
                    };

                    this.mediaRecorder.onstop = () => {
                        console.log('üìπ MediaRecorder stopped, processing audio...');
                        this.processRecording();
                    };

                    this.mediaRecorder.onerror = (event) => {
                        console.error('‚ùå MediaRecorder error:', event.error);
                        this.showError('Recording error: ' + event.error);
                    };

                    this.mediaRecorder.onstart = () => {
                        console.log('‚ñ∂Ô∏è MediaRecorder started successfully');
                    };

                    console.log('‚úÖ MediaRecorder setup complete');

                } catch (error) {
                    console.error('‚ùå Error setting up MediaRecorder:', error);
                    throw error;
                }
            }

            // FIXED: Enhanced audio analysis with better debugging
            analyzeAudioEnhanced() {
                if (!this.isListening || !this.analyser) {
                    console.log('üõë AUDIO ANALYSIS STOPPED: isListening=' + this.isListening + ', analyser=' + !!this.analyser);
                    return;
                }

                this.frameCounter++;
                requestAnimationFrame(() => this.analyzeAudioEnhanced());

                // FIXED: Get FRESH data every frame
                this.analyser.getByteFrequencyData(this.dataArray);
                this.analyser.getByteTimeDomainData(this.timeDataArray);

                // FIXED: Improved audio level calculation
                let rms = 0;
                for (let i = 0; i < this.timeDataArray.length; i++) {
                    const amplitude = (this.timeDataArray[i] - 128) / 128; // -1 to 1
                    rms += amplitude * amplitude;
                }
                const audioLevel = Math.sqrt(rms / this.timeDataArray.length);

                // FIXED: Update visualizer with frequency data (more responsive)
                this.updateVoiceVisualizerFixed(this.dataArray);

                // FIXED: Enhanced Voice Activity Detection
                this.processVoiceActivityFixed(audioLevel);

                // FIXED: Debug every 60 frames to confirm it's running
                if (this.frameCounter % 60 === 0) {
                    console.log(`üéôÔ∏è AUDIO ANALYSIS RUNNING: Frame ${this.frameCounter}, Level: ${audioLevel.toFixed(3)}, Recording: ${this.isRecording}`);
                }
            }

            // FIXED: Voice visualizer that actually works
            updateVoiceVisualizerFixed(frequencyData) {
                const bars = document.querySelectorAll('.voice-bar');
                if (bars.length === 0) return;

                const step = Math.floor(frequencyData.length / bars.length);

                let maxValue = 0;
                let totalActivity = 0;

                bars.forEach((bar, index) => {
                    const value = frequencyData[index * step] || 0;
                    maxValue = Math.max(maxValue, value);
                    totalActivity += value;

                    const height = (value / 255) * 100;
                    bar.style.height = `${Math.max(4, height)}%`;
                    bar.classList.toggle('active', value > 15);  // Even lower threshold
                });

                // FIXED: Update debug info every 60 frames with more detail
                if (this.frameCounter % 60 === 0) {
                    const avgActivity = totalActivity / bars.length;
                    const debugPanel = document.getElementById('visualizerDebug');
                    if (debugPanel) {
                        debugPanel.textContent = `max:${maxValue}, avg:${avgActivity.toFixed(1)}, frame:${this.frameCounter}`;
                    }
                    console.log(`üéµ VISUALIZER: max=${maxValue}, avg=${avgActivity.toFixed(1)}, activeBars=${document.querySelectorAll('.voice-bar.active').length}`);
                }
            }

            // FIXED: Enhanced voice activity detection with better silence logic
            processVoiceActivityFixed(audioLevel) {
                const speechThreshold = 0.08;  // FIXED: Lower threshold for better detection
                const silenceDuration = this.vadConfig?.timing?.silence_duration_ms || 2000;
                const maxDuration = this.vadConfig?.timing?.max_recording_duration_ms || 30000;

                const isSpeech = audioLevel > speechThreshold;
                const now = Date.now();

                // FIXED: Always update debug panel
                this.updateDebugPanelFixed(audioLevel, speechThreshold, isSpeech);

                // FIXED: More frequent logging to see what's happening
                if (this.frameCounter % 50 === 0) {
                    console.log(`üéôÔ∏è VAD CHECK: Level=${audioLevel.toFixed(3)}, Threshold=${speechThreshold}, Speech=${isSpeech}, SpeechDetected=${this.speechDetected}, Recording=${this.isRecording}`);
                }

                if (isSpeech) {
                    if (!this.speechDetected) {
                        // FIXED: Speech just started
                        console.log('üó£Ô∏è üî• SPEECH STARTED! Audio level:', audioLevel.toFixed(3));
                        this.speechDetected = true;
                        this.speechStartTime = now;
                        this.silenceStartTime = null;

                        this.updateConversationState('listening', 'üó£Ô∏è Recording your answer...');
                    } else {
                        // FIXED: Speech continuing - reset silence timer
                        if (this.silenceStartTime) {
                            console.log('üîÑ Speech resumed, resetting silence timer');
                            this.silenceStartTime = null;
                        }
                    }
                } else {
                    // FIXED: No speech detected - silence logic
                    if (this.speechDetected) {
                        // We had speech before, now it's quiet
                        if (!this.silenceStartTime) {
                            // FIXED: Just went silent
                            this.silenceStartTime = now;
                            console.log('ü§´ ‚è∞ SILENCE STARTED. Will auto-stop in', silenceDuration, 'ms');
                        } else {
                            // FIXED: Check if we've been silent long enough
                            const silenceDurationMs = now - this.silenceStartTime;

                            // FIXED: Log silence progress more frequently
                            if (this.frameCounter % 30 === 0) {
                                console.log(`‚è≥ Silence: ${silenceDurationMs}ms / ${silenceDuration}ms`);
                            }

                            if (silenceDurationMs >= silenceDuration) {
                                console.log('üõë ‚úÖ SILENCE THRESHOLD REACHED! Duration:', silenceDurationMs, 'ms - STOPPING NOW!');
                                this.stopListening();
                                return;
                            }
                        }
                    }
                }

                // FIXED: Safety timeout check
                if (this.isRecording && this.speechStartTime) {
                    const recordingDuration = now - this.speechStartTime;
                    if (recordingDuration > maxDuration) {
                        console.log('‚è∞ üõë MAXIMUM RECORDING TIME REACHED:', recordingDuration, 'ms');
                        this.stopListening();
                    }
                }
            }

            // FIXED: Enhanced debug panel
            updateDebugPanelFixed(audioLevel, threshold, isSpeech) {
                const debugPanel = document.getElementById('debugPanel');
                if (!debugPanel || debugPanel.style.display === 'none') return;

                const now = Date.now();
                const silenceDurationMs = this.silenceStartTime ? now - this.silenceStartTime : 0;

                document.getElementById('audioLevelDebug').textContent = audioLevel.toFixed(3);
                document.getElementById('thresholdDebug').textContent = threshold.toFixed(3);
                document.getElementById('speechDebug').textContent = isSpeech.toString();
                document.getElementById('silenceDebug').textContent = silenceDurationMs + 'ms';
                document.getElementById('recordingStateDebug').textContent = this.mediaRecorder ? this.mediaRecorder.state : 'none';
                document.getElementById('audioChunksDebug').textContent = this.audioChunks ? this.audioChunks.length : 0;
                document.getElementById('isListeningDebug').textContent = this.isListening.toString();
            }

            toggleDebug() {
                const debugPanel = document.getElementById('debugPanel');
                if (debugPanel) {
                    debugPanel.style.display = debugPanel.style.display === 'none' ? 'block' : 'none';
                }
            }

            pauseConversation() {
                console.log('‚è∏Ô∏è Pausing conversation...');

                // Stop any current speech
                if (this.speechSynthesis) {
                    this.speechSynthesis.cancel();
                }

                // Stop listening
                if (this.isListening) {
                    this.stopListening();
                }

                this.updateConversationState('idle', '‚è∏Ô∏è Conversation paused');

                // Show resume button
                const controls = document.querySelector('.conversation-controls');
                const resumeBtn = document.getElementById('resumeBtn');
                if (!resumeBtn) {
                    const resumeButton = document.createElement('button');
                    resumeButton.className = 'conv-button primary';
                    resumeButton.id = 'resumeBtn';
                    resumeButton.onclick = () => this.resumeConversation();
                    resumeButton.innerHTML = '‚ñ∂Ô∏è Resume';
                    controls.prepend(resumeButton);
                }

                // Disable other controls
                this.disableControls(['repeatBtn', 'hintBtn', 'skipBtn', 'stopRecordingBtn']);
            }

            resumeConversation() {
                console.log('‚ñ∂Ô∏è Resuming conversation...');

                // Remove resume button
                const resumeBtn = document.getElementById('resumeBtn');
                if (resumeBtn) {
                    resumeBtn.remove();
                }

                // Re-enable controls
                this.enableControls(['repeatBtn', 'hintBtn', 'skipBtn']);

                // Restart listening
                this.startListening();
            }

            exitConversation() {
                console.log('üö™ Exiting conversation...');

                if (confirm('Are you sure you want to exit the conversation?')) {
                    // Stop everything
                    if (this.speechSynthesis) {
                        this.speechSynthesis.cancel();
                    }

                    if (this.isListening) {
                        this.stopListening();
                    }

                    // Go back to manual mode
                    window.location.href = '/';
                }
            }

            forceStartListening() {
                console.log('üîß Force starting listening (debug)...');
                this.startListening();
            }

            stopListening() {
                if (!this.isListening) {
                    console.log('‚ö†Ô∏è stopListening called but not currently listening');
                    return;
                }

                console.log('üõë Stopping listening...');

                this.isListening = false;

                // Hide the manual stop button
                const stopBtn = document.getElementById('stopRecordingBtn');
                if (stopBtn) stopBtn.style.display = 'none';

                // FIXED: Better MediaRecorder cleanup
                if (this.isRecording && this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    console.log('üìπ Stopping MediaRecorder...');
                    try {
                        this.mediaRecorder.stop();
                        this.isRecording = false;
                    } catch (error) {
                        console.error('‚ùå Error stopping MediaRecorder:', error);
                    }
                } else {
                    console.log('‚ö†Ô∏è MediaRecorder not recording, state:', this.mediaRecorder?.state);
                }

                // FIXED: Properly stop audio stream and cleanup
                if (this.mediaRecorder && this.mediaRecorder.stream) {
                    this.mediaRecorder.stream.getTracks().forEach(track => {
                        console.log('üîá Stopping audio track:', track.kind, track.readyState);
                        track.stop();
                    });
                }

                // FIXED: Clean up audio context
                if (this.audioContext && this.audioContext.state !== 'closed') {
                    try {
                        this.audioContext.close();
                        console.log('üîá Audio context closed');
                    } catch (error) {
                        console.error('‚ö†Ô∏è Error closing audio context:', error);
                    }
                }

                // FIXED: Reset audio components
                this.audioContext = null;
                this.analyser = null;
                this.mediaRecorder = null;

                this.updateConversationState('processing', 'üß† Processing your answer...');
                this.disableControls(['repeatBtn', 'hintBtn', 'skipBtn', 'stopRecordingBtn']);
            }

            async processRecording() {
                try {
                    console.log('üé¨ Processing recording... Audio chunks:', this.audioChunks.length);
                    console.log('üéØ Current MIME type:', this.currentMimeType);

                    if (this.audioChunks.length === 0) {
                        console.error('‚ùå No audio chunks recorded!');
                        this.showError('No audio was recorded. Please try speaking louder or check your microphone.');
                        return;
                    }

                    const audioBlob = new Blob(this.audioChunks, { type: this.currentMimeType });
                    console.log('üì¶ Audio blob created:', audioBlob.size, 'bytes, type:', this.currentMimeType);

                    if (audioBlob.size < 1000) {
                        console.error('‚ùå Audio recording too short:', audioBlob.size, 'bytes');
                        this.showError('Recording too short. Please try speaking for longer.');

                        // Restart listening after error
                        setTimeout(() => {
                            this.startListening();
                        }, 2000);
                        return;
                    }

                    const formData = new FormData();

                    // Use appropriate file extension based on MIME type
                    let fileName = 'recording.webm'; // default
                    if (this.currentMimeType.includes('wav')) {
                        fileName = 'recording.wav';
                    } else if (this.currentMimeType.includes('mp4')) {
                        fileName = 'recording.mp4';
                    }

                    formData.append('audio', audioBlob, fileName);

                    console.log('üì§ Submitting audio to server as:', fileName);

                    const response = await fetch('/api/conversation/submit-answer', {
                        method: 'POST',
                        body: formData
                    });

                    if (!response.ok) {
                        const errorData = await response.json();
                        throw new Error(errorData.error || 'Server error');
                    }

                    const result = await response.json();
                    console.log('‚úÖ Answer processed successfully:', result);

                    // Show result and speak feedback
                    await this.showResult(result);

                } catch (error) {
                    console.error('‚ùå Error processing recording:', error);
                    this.showError('Error processing your answer: ' + error.message);

                    // Restart listening after error
                    setTimeout(() => {
                        this.startListening();
                    }, 2000);
                }
            }

            async showResult(result) {
                const resultDiv = document.getElementById('conversationResult');
                const analysis = result.analysis || {};

                resultDiv.innerHTML = `
                    <div class="conversation-result">
                        <div class="result-score">Score: ${Math.round(analysis.overall_score || 0)}/100</div>
                        <div class="result-feedback">"${result.transcription || 'No speech detected'}"</div>
                        <div><strong>Correct answer:</strong> ${result.figure_name}</div>
                    </div>
                `;
                resultDiv.style.display = 'block';

                // Speak the feedback (simulated - would come from backend)
                const feedbackText = this.generateFeedback(result);

                this.updateConversationState('speaking', 'ü§ñ Providing feedback...');

                await this.speak(feedbackText, () => {
                    // FIXED: Auto-advance after feedback, but keep voice "next" as option
                    console.log('üöÄ Feedback complete - auto-advancing in 3 seconds...');

                    // Show manual controls immediately
                    this.showManualNext();
                    this.startSimpleVoiceListener(); // Keep voice "next" as option

                    // Auto-advance after 3 seconds
                    this.autoAdvanceTimer = setTimeout(() => {
                        if (this.conversationState === 'waiting') {
                            console.log('‚è≠Ô∏è Auto-advancing to next question...');
                            this.nextQuestion();
                        }
                    }, 3000);

                    this.updateConversationState('waiting', '‚è≥ Auto-advancing in 3 seconds (or say "next")...');
                });
            }

            generateFeedback(result) {
                const accuracy = result.analysis?.accuracy_score || 0;
                const transcription = result.transcription || '';
                const figureName = result.figure_name || 'the figure';

                if (accuracy >= 90) {
                    return `Perfect! You said "${transcription}" and that's exactly right. Great job!`;
                } else if (accuracy >= 70) {
                    return `Correct! You said "${transcription}" - that's ${figureName}. Well done!`;
                } else if (accuracy >= 40) {
                    return `Close! You said "${transcription}" - I was looking for ${figureName}.`;
                } else {
                    return `Not quite. You said "${transcription}", but the answer was ${figureName}. Keep trying!`;
                }
            }

            // REMOVED: waitForNext function - now using auto-advance with voice option

            // FIXED: Simple voice listener that doesn't spam
            async startSimpleVoiceListener() {
                if (!this.permissionsGranted || this.conversationState !== 'waiting') return;

                try {
                    console.log('üëÇ Starting simple voice listener for "next"...');

                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                    // Use the SAME recording setup as answers but shorter
                    const recorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
                    const chunks = [];

                    recorder.ondataavailable = (event) => {
                        if (event.data.size > 0) chunks.push(event.data);
                    };

                    recorder.onstop = async () => {
                        stream.getTracks().forEach(track => track.stop());

                        if (chunks.length === 0 || this.conversationState !== 'waiting') return;

                        const audioBlob = new Blob(chunks, { type: 'audio/webm' });
                        if (audioBlob.size < 500) return; // Too short

                        // Use the SAME transcription endpoint as answers
                        const formData = new FormData();
                        formData.append('audio', audioBlob, 'next-command.webm');

                        try {
                            const response = await fetch('/api/conversation/submit-answer', {
                                method: 'POST',
                                body: formData
                            });

                            if (response.ok) {
                                const result = await response.json();
                                const transcript = result.transcription?.toLowerCase() || '';

                                // Check if they said "next"
                                if (transcript.includes('next')) {
                                    console.log('‚úÖ "Next" command detected!');
                                    this.nextQuestion();
                                    return;
                                }
                            }
                        } catch (error) {
                            console.log('‚ö†Ô∏è Voice command error:', error);
                        }

                        // Restart listening if still waiting
                        if (this.conversationState === 'waiting') {
                            setTimeout(() => this.startSimpleVoiceListener(), 1000);
                        }
                    };

                    recorder.start();

                    // Stop after 4 seconds
                    setTimeout(() => {
                        if (recorder.state === 'recording') recorder.stop();
                    }, 4000);

                } catch (error) {
                    console.error('‚ùå Voice listener error:', error);
                }
            }

            showManualNext() {
                const controls = document.querySelector('.conversation-controls');

                // Check if next button already exists
                if (document.getElementById('nextQuestionBtn')) return;

                const nextButton = document.createElement('button');
                nextButton.className = 'conv-button primary';
                nextButton.id = 'nextQuestionBtn';
                nextButton.onclick = () => this.nextQuestion();
                nextButton.innerHTML = '‚û°Ô∏è Next Question';
                nextButton.style.marginLeft = '10px';

                controls.appendChild(nextButton);
            }

            async nextQuestion() {
                console.log('‚û°Ô∏è MOVING TO NEXT QUESTION...');

                // FIXED: Clear auto-advance timer
                if (this.autoAdvanceTimer) {
                    clearTimeout(this.autoAdvanceTimer);
                    this.autoAdvanceTimer = null;
                }

                // FIXED: Stop any command listeners that might be running
                if (this.commandRecorder && this.commandRecorder.state === 'recording') {
                    try {
                        this.commandRecorder.stop();
                    } catch (error) {
                        console.log('‚ö†Ô∏è Error stopping command recorder:', error);
                    }
                }

                // Remove the next button
                const nextBtn = document.getElementById('nextQuestionBtn');
                if (nextBtn) {
                    nextBtn.remove();
                }

                // FIXED: Reset conversation state
                this.conversationState = 'idle';

                // Load new game state
                await this.loadGameState();

                if (this.gameState.is_complete) {
                    this.renderGameComplete();
                } else {
                    this.renderConversationInterface();
                    await this.startConversation();
                }
            }

            updateConversationState(state, text) {
                const stateElement = document.getElementById('conversationState');
                if (stateElement) {
                    stateElement.className = `conversation-state state-${state}`;
                    stateElement.textContent = text;
                }
                this.conversationState = state;
            }

            enableControls(controlIds) {
                controlIds.forEach(id => {
                    const element = document.getElementById(id);
                    if (element) element.disabled = false;
                });
            }

            disableControls(controlIds) {
                controlIds.forEach(id => {
                    const element = document.getElementById(id);
                    if (element) element.disabled = true;
                });
            }

            async repeatQuestion() {
                await this.speakQuestion();
            }

            async getHint() {
                const figure = this.gameState.current_figure;
                const hintText = `Here's a hint: ${figure.hint}`;
                await this.speak(hintText);
            }

            async skipQuestion() {
                const figure = this.gameState.current_figure;
                const skipText = `No problem! The answer was ${figure.name}.`;
                await this.speak(skipText, () => {
                    this.waitForNext({ is_final_figure: false });
                });
            }

            async restartGame() {
                try {
                    const response = await fetch('/api/restart-game', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ mode: 'classic' })
                    });

                    if (response.ok) {
                        location.reload();
                    }
                } catch (error) {
                    console.error('Error restarting game:', error);
                }
            }

            renderGameComplete() {
                const container = document.getElementById('gameContainer');

                // FIXED: Get final stats from last result or calculate from game state
                let finalStats = this.finalStats || {};
                if (!finalStats.total_score && this.gameState) {
                    // Calculate stats from current game state
                    finalStats = {
                        total_score: Math.round(this.gameState.score || 0),
                        average_score: Math.round((this.gameState.score || 0) / Math.max(1, this.gameState.progress?.current || 1)),
                        attempts: this.gameState.progress?.current || 0,
                        max_streak: this.gameState.streak || 0
                    };
                }

                container.innerHTML = `
                    <div class="conversation-card">
                        <h2 style="text-align: center; margin-bottom: 20px;">üéâ Congratulations!</h2>
                        <p style="text-align: center; font-size: 1.2rem; margin-bottom: 30px;">You've completed all the historical figures!</p>

                        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(150px, 1fr)); gap: 20px; margin: 30px 0;">
                            <div style="background: rgba(255,255,255,0.2); padding: 20px; border-radius: 15px; text-align: center;">
                                <div style="font-size: 2rem; font-weight: bold; color: #FFD700;">${finalStats.total_score || 0}</div>
                                <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 5px;">Total Score</div>
                            </div>
                            <div style="background: rgba(255,255,255,0.2); padding: 20px; border-radius: 15px; text-align: center;">
                                <div style="font-size: 2rem; font-weight: bold; color: #FFD700;">${finalStats.average_score || 0}</div>
                                <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 5px;">Average Score</div>
                            </div>
                            <div style="background: rgba(255,255,255,0.2); padding: 20px; border-radius: 15px; text-align: center;">
                                <div style="font-size: 2rem; font-weight: bold; color: #FFD700;">${finalStats.attempts || 0}</div>
                                <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 5px;">Figures Named</div>
                            </div>
                            <div style="background: rgba(255,255,255,0.2); padding: 20px; border-radius: 15px; text-align: center;">
                                <div style="font-size: 2rem; font-weight: bold; color: #FFD700;">${finalStats.max_streak || 0}</div>
                                <div style="font-size: 0.9rem; opacity: 0.9; margin-top: 5px;">Best Streak</div>
                            </div>
                        </div>

                        <div style="text-align: center; margin-top: 30px;">
                            <button class="conv-button primary" onclick="game.restartGame()">
                                üéÆ Start New Game
                            </button>
                        </div>

                        <div style="text-align: center; margin-top: 20px; font-size: 0.9rem; opacity: 0.8;">
                            üí∞ Cost per game: $0.00 (100% local processing!)
                        </div>
                    </div>
                `;
            }

            showError(message) {
                const container = document.getElementById('gameContainer');
                container.innerHTML = `
                    <div class="conversation-card">
                        <div class="error-message">${message}</div>
                        <div style="text-align: center; margin-top: 20px;">
                            <button class="conv-button primary" onclick="location.reload()">üîÑ Retry</button>
                        </div>
                    </div>
                `;
            }
        }

        // Global functions
        let game;

        function setMode(mode) {
            document.getElementById('manualMode').classList.toggle('active', mode === 'manual');
            document.getElementById('conversationalMode').classList.toggle('active', mode === 'conversational');

            if (mode === 'manual') {
                // Switch to original manual mode
                window.location.href = '/';
            } else {
                // Stay in conversational mode
                if (!game) {
                    game = new ConversationalHistoryGame();
                }
            }
        }

        // Initialize conversational game
        window.addEventListener('load', () => {
            game = new ConversationalHistoryGame();
        });
    </script>
</body>
</html>